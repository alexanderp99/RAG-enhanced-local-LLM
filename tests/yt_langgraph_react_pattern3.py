# -*- coding: utf-8 -*-
"""YT LangGraph ReAct Pattern.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14ncV0nviLcP9IDzmFSRGSXb7Bgpz212v
"""

from langchain_community.tools import DuckDuckGoSearchResults
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_ollama import ChatOllama
from langgraph.prebuilt import ToolNode
from pydantic import BaseModel

from modelTypes import Modeltype


def call_reasoning_graph(my_llm, sys_message, human_message):
    search = DuckDuckGoSearchResults()

    def search_in_document(query: str) -> str:
        """Query the documents for content

        Args:
            query: query Question
        """
        return "Dogs are allowed in the establishment. The price for one dog is 5 euros per night."

    def multiply(a: int, b: int) -> int:
        """Multiply a and b.

        Args:
            a: first int
            b: second int
        """
        return a * b

    # This will be a tool
    def add(a: int, b: int) -> int:
        """Adds a and b.

        Args:
            a: first int
            b: second int
        """
        return a + b

    def divide(a: int, b: int) -> float:
        """Divide a and b.

        Args:
            a: first int
            b: second int
        """
        return a / b

    import yfinance as yf

    def get_stock_price(ticker: str) -> float:
        """Gets a stock price from Yahoo Finance.

        Args:
            ticker: ticker str
        """
        # """This is a tool for getting the price of a stock when passed a ticker symbol"""
        stock = yf.Ticker(ticker)
        return stock.info['previousClose']

    tools = [add, multiply, divide, get_stock_price, search, search_in_document]
    llm_with_tools = my_llm.bind_tools(tools)

    # Node
    def reasoner(state):
        # query = state["query"]
        messages = state["messages"]
        # System message
        no_human_message_added = not (any([isinstance(each_message, HumanMessage) for each_message in messages]))
        sys_msg = sys_message
        message = human_message
        if no_human_message_added:
            messages.append(message)
        result = [llm_with_tools.invoke([sys_msg] + messages)]
        return {"messages": result}

    from typing import Annotated, TypedDict, Literal, Union, Any
    import operator
    from langchain_core.messages import AnyMessage

    class GraphState(TypedDict):
        """State of the graph."""
        query: str
        finance: str
        final_answer: str
        # intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]
        messages: Annotated[list[AnyMessage], operator.add]

    from langgraph.graph import START, StateGraph

    # Graph
    workflow = StateGraph(GraphState)

    # Add Nodes
    workflow.add_node("reasoner", reasoner)
    workflow.add_node("tools", ToolNode(tools))  # for the tools

    # Add Edges
    workflow.add_edge(START, "reasoner")

    def tools_condition(
            state: Union[list[AnyMessage], dict[str, Any], BaseModel],
            messages_key: str = "messages",
    ) -> Literal["tools", "__end__"]:
        """Use in the conditional_edge to route to the ToolNode if the last message"""
        if isinstance(state, list):
            ai_message = state[-1]
        elif isinstance(state, dict) and (messages := state.get(messages_key, [])):
            ai_message = messages[-1]
        elif messages := getattr(state, messages_key, []):
            ai_message = messages[-1]
        else:
            raise ValueError(f"No messages found in input state to tool_edge: {state}")
        if hasattr(ai_message, "tool_calls") and len(ai_message.tool_calls) > 0:
            return "tools"
        return "__end__"

    workflow.add_conditional_edges(
        "reasoner",
        # If the latest message (result) from node reasoner is a tool call -> tools_condition routes to tools
        # If the latest message (result) from node reasoner is a not a tool call -> tools_condition routes to END
        tools_condition,
    )
    workflow.add_edge("tools", "reasoner")
    react_graph = workflow.compile()

    result = react_graph.invoke({"query": human_message.content})
    return result


"""


response = react_graph.invoke({"query": "What is 2 times Brad Pitt's age (43)?", "messages": []})

response['messages'][-1].pretty_print()



response = react_graph.invoke({"query": "What is the stock price of Apple divided by two??", "messages": []})

for m in response['messages']:
    m.pretty_print()

response = react_graph.invoke({"query": "What is the color of the sky?", "messages": []})
response['messages'][-1].pretty_print()
"""

"""response = react_graph.invoke(
    {"query": "A dog costs me 5 euros per night. How much do i have to pay if i have 2 dogs?",
     "messages": []})
print(response['messages'])"""

llm = ChatOllama(model=Modeltype.LLAMA3_1_8B.value, temperature=0)
"""sys_msg = SystemMessage(
    "You are a helpful assistant. You can use web search, search for the response in the documents and perform arithmetic on a set of inputs. For the first question, use the tool that searches in a document")"""
"""sys_msg = SystemMessage(
    "You are a helpful assistant. You can perform arithmetic on a set of inputs.")"""

"""sys_msg = SystemMessage(
    "You are a helpful assistant, that has access to documents. You can search for context in the documents and perform arithmetic on a set of inputs. For the first question, use the tool that searches in a document")"""

sys_msg = SystemMessage(
    """You are a helpful assistant with access to tools. You can search for relevant information using the provided tools and perform arithmetic calculations. 
For each question, determine if you can answer the question directly based on your general knowledge, or If necessary Use the `search_in_document` tool to find the necessary information within the available documents.""")

# human_message = HumanMessage("What is 1 * 9?")

# human_message = HumanMessage("A single dog costs me 5 euros per night in a hotel. How much do i have to pay if i have 2 dogs and want to stay one night?")

human_message = HumanMessage("Which doctor is also available on Wednesday if Dr. Christoph FÃ¼rthauer has closed?")

res = call_reasoning_graph(llm, sys_msg, human_message)

print(res["messages"][1].lc_attributes["tool_calls"][0]["args"]["query"])
print(res)
